{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect house damage or associated risk from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "#! pip install pytube\n",
    "from pytube import YouTube\n",
    "#! conda install -c conda-forge imageio\n",
    "import imageio\n",
    "#! pip install moviepy\n",
    "from moviepy.editor import *\n",
    "from ipywidgets import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download youtube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/manas/data/Video'\n",
    "url = 'https://www.youtube.com/watch?v=WgrL79xPOYo'\n",
    "save_fn = 'Open House Tour1'\n",
    "yt = YouTube(url).streams.first().download(output_path=filepath, filename=save_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Video, save to images and annotate them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "I have combined 8 models from different modeling teams to detect any damage/risk in a house. For the dead lanscape model I have retrained the model and included a none category. The accuracy received is 0.89. Time permitted, I could have increased accuracy of this model.\n",
    "\n",
    "The steps of the project are as follows:\n",
    "\n",
    "Step 1: Detect childproof fall risk classes: balcony, bathtub, stairs, swimming pool, window, none. If the detected category is 'none' write nothing on image.\n",
    "\n",
    "Step 2: Detect (dead) landscape type, e.g., dead, healthy or none. If the detected category is 'none', apply exterior building damage model. If the detected category is healthy, apply overgrown landscape model\n",
    "\n",
    "Step 3: If the image category (clean, overgrown) using overgrown landscape model is 'clean' write nothing on image.\n",
    "\n",
    "Step 4: If the image category using exterior building damage is 'none' implement these models: wall stain model, furniture stain model, childproof heavy object model, childproof electrical model. These models would run in parallel. If the detected category from those models are 'safe' or 'clean' those would not be written on the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vidcap = cv2.VideoCapture('C:/Users/manas/data/building_data/Southwest Florida Home Inspection 10.25-10.40.mp4')\n",
    "vidcap = cv2.VideoCapture('C:/Users/manas/data/Video/Open House Tour1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_folder_path = 'C:/Users/manas/data/video_frames/Open_house_tour_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to run for getting rid of attribute error\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "class OverSamplingCallback(LearnerCallback):\n",
    "   def __init__(self,learn:Learner,weights:torch.Tensor=None):\n",
    "       super().__init__(learn)\n",
    "       self.labels = self.learn.data.train_dl.dataset.y.items\n",
    "       _, counts = np.unique(self.labels,return_counts=True)\n",
    "       self.weights = (weights if weights is not None else\n",
    "                       torch.DoubleTensor((1/counts)[self.labels]))\n",
    "       self.label_counts = np.bincount([self.learn.data.train_dl.dataset.y[i].data for i in range(len(self.learn.data.train_dl.dataset))])\n",
    "       self.total_len_oversample = int(self.learn.data.c*np.max(self.label_counts))\n",
    "   def on_train_begin(self, **kwargs):\n",
    "       self.learn.data.train_dl.dl.batch_sampler = BatchSampler(WeightedRandomSampler(self.weights,self.total_len_oversample), self.learn.data.train_dl.batch_size,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading learner objects\n",
    "learn_cf = load_learner('C:/Users/manas/data/childproofing_fall')\n",
    "learn_dl = load_learner('C:/Users/manas/data/dead_landscape_model')\n",
    "learn_ol = load_learner('C:/Users/manas/data/overgrown_landscape')\n",
    "learn_ol.to_fp32()\n",
    "learn_ed = load_learner('C:/Users/manas/data/building_data')\n",
    "learn_ws = load_learner('C:/Users/manas/data/wall_stain')\n",
    "learn_fs = load_learner('C:/Users/manas/data/furniture_stain')\n",
    "learn_ch = load_learner('C:/Users/manas/data/childproffing_heavy_object')\n",
    "learn_ce = load_learner('C:/Users/manas/data/childproofing_electrical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bldg_detect(learn, frame_path):\n",
    "    prediction = learn.predict(open_image(frame_path))\n",
    "    category = prediction[0]\n",
    "    probability = \"{0:.4f}\".format(max(prediction[2]))\n",
    "    return category, probability    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/manas/data/video_frames_text/Open_house_tour1/'\n",
    "count = 0\n",
    "success = 1\n",
    "while success:\n",
    "    success,frame = vidcap.read()\n",
    "    frame_path = frame_folder_path + f'frame{count}.jpg'\n",
    "    cv2.imwrite(frame_path,frame)\n",
    "    #print(frame_path)\n",
    "    \n",
    "    # model prediction: childproof fall\n",
    "    category_cf, probability_cf = bldg_detect(learn_cf,frame_path)\n",
    "    if str(category_cf) =='none':\n",
    "        category_fall = ''\n",
    "    else:\n",
    "        category_fall = 'fall risk ' + str(category_cf)\n",
    "        \n",
    "        \n",
    "    # model prediction: dead landscape\n",
    "    category_dl, probability_dl = bldg_detect(learn_dl,frame_path)\n",
    "    if str(category_dl) =='none':\n",
    "        category_l = ''\n",
    "        #model prediction: exterior damage\n",
    "        category_ed, probability_ed = bldg_detect(learn_ed,frame_path)    \n",
    "\n",
    "        if str(category_ed) == 'none':\n",
    "            # model prediction for wall stain\n",
    "            category_ws, probability_ws = bldg_detect(learn_ws,frame_path)\n",
    "            if str(category_ws) == 'clean':\n",
    "                category_wall = ''\n",
    "            else:\n",
    "                category_wall = 'wall ' + str(category_ws)\n",
    "            # model prediction for furniture stain    \n",
    "            category_fs, probability_fs = bldg_detect(learn_fs,frame_path)\n",
    "            if str(category_fs) == 'clean':\n",
    "                category_furn = ''\n",
    "            else:\n",
    "                category_furn = 'furniture ' + str(category_fs)\n",
    "\n",
    "            # model prediction for heavyobject risk\n",
    "            category_ch, probability_ch = bldg_detect(learn_ch,frame_path)\n",
    "            if str(category_ch) == 'safe_furniture' or str(category_ch) == 'safe_kitchen' or str(category_ch) == 'safe_tv' or str(category_ch) == 'safe_furniture;safe_kitchen' or str(category_ch) == 'safe_kitchen;safe_furniture' or str(category_ch) == 'safe_furniture;safe_tv' or str(category_ch) == 'safe_tv;safe_furniture':\n",
    "                category_heavy = ''\n",
    "            \n",
    "            else:\n",
    "                category_heavy = str(category_ch)\n",
    "\n",
    "            # model prediction for electrical risk\n",
    "            category_ce, probability_ce = bldg_detect(learn_ce,frame_path)\n",
    "            if str(category_ce) == 'childproofed':\n",
    "                category_electric = ''\n",
    "            else:\n",
    "                category_electric = 'electrical - ' + str(category_ce)\n",
    "\n",
    "            #writing to category building landscape and building risk\n",
    "            #category_l = str(category_wall) +'| ' + str(category_furn) +'| ' + str(category_heavy) + '| '+ str(category_electric)\n",
    "            if str(category_wall) != '':\n",
    "                category_l = category_l + str(category_wall) \n",
    "            if str(category_furn) != '':\n",
    "                if category_l != '':\n",
    "                    category_l = category_l + ' | ' \n",
    "                category_l =category_l + str(category_furn) \n",
    "   \n",
    "            if str(category_heavy) != '':\n",
    "                if category_l != '':\n",
    "                    category_l = category_l + ' | ' \n",
    "                category_l =category_l + str(category_heavy) \n",
    "\n",
    "            if str(category_electric) != '':\n",
    "                if category_l != '':\n",
    "                    category_l = category_l + ' | '     \n",
    "                category_l =category_l + str(category_electric) \n",
    "                \n",
    "        else:\n",
    "            category_l = str(category_ed)\n",
    "    else:\n",
    "        category_l = 'landscape ' + str(category_dl)\n",
    "    \n",
    "    # model prediction for overgrown landscape\n",
    "    if str(category_dl) == \"healthy\":\n",
    "        category_ol, probability_ol = bldg_detect(learn_ol,frame_path)\n",
    "        if str(category_ol) =='clean':\n",
    "            category_l = ''\n",
    "        else:\n",
    "            category_l = 'landscape ' + str(category_ol)\n",
    "    \n",
    "    # writing to category child fall risk, building landscape and building risk\n",
    "    #category = str(category_fall) + '| ' + str(category_l)\n",
    "    \n",
    "    category = ''\n",
    "    \n",
    "    if str(category_fall) != '':\n",
    "        category = str(category_fall)\n",
    "        \n",
    "    if str(category_l) != '':\n",
    "        if category != '':\n",
    "            category = category + ' | ' + str(category_l)\n",
    "        else:\n",
    "            category = str(category_l)\n",
    "    \n",
    "    \n",
    "    # writing category text on image \n",
    "    \n",
    "    if category != '':\n",
    "        #text = f'{category} \\n {probability}'\n",
    "        text = f'{category}'\n",
    "\n",
    "        #Writing on iamge\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "        # set the rectangle background to white\n",
    "        rectangle_bgr = (255, 255, 255)\n",
    "        # get the width and height of the text box\n",
    "        (text_width, text_height) = cv2.getTextSize(text, font, fontScale=1.0, thickness=1)[0]\n",
    "        # set the text start position\n",
    "        text_offset_x = 5\n",
    "        text_offset_y = 16\n",
    "        # make the coords of the box with a small padding (change  coordinate to adjust)\n",
    "        box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 10, text_offset_y + text_height + 10))\n",
    "        cv2.rectangle(frame, box_coords[0], box_coords[1], rectangle_bgr, cv2.FILLED)\n",
    "\n",
    "        \n",
    "        img_with_text = cv2.putText(frame,text,(10, 40),\n",
    "            font,1,(255,0,0),2,cv2.LINE_AA)\n",
    "\n",
    "        # Save the image\n",
    "\n",
    "        cv2.imwrite(filepath + f'frame{count}.jpg',img_with_text)\n",
    "\n",
    "    else:\n",
    "        cv2.imwrite(filepath + f'frame{count}.jpg',frame)\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.waitKey(1)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From image to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathIn= 'C:/Users/manas/data/video_frames_text/Open_house_tour1/'\n",
    "pathOut = 'C:/Users/manas/data/Video/Open_house_tour1_text.mp4'\n",
    "fps = 20\n",
    "frame_array = []\n",
    "files = [f for f in os.listdir(pathIn)]\n",
    "\n",
    "for i in range(len(files)):\n",
    "    filename=pathIn + 'frame'+str(i+8)+ '.jpg'\n",
    "    \n",
    "    #reading each files\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    \n",
    "    #inserting the frames into an image array\n",
    "    frame_array.append(img)\n",
    "    \n",
    "out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "for i in range(len(frame_array)):\n",
    "    # writing to a image array\n",
    "    out.write(frame_array[i])\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Many models including ours fall short in classifying the image properly. The main problem lies on how the models were trained individually earlier. For example, our exterior bulding damage model, - although we had several damage categories and a 'none' category, we included mostly undamaged exterior building parts in the trainset, and no building interior images. So, the model sometime fails to classify the interior images correctly. Also, many rotten window frames were of white colour which creates bias in classification. Sometimes reflections on window are classified as broken window glass. We need to have much larger dataset with different image types to train a better model. I could have included other models, e.g., water damage, structural damage etc to make this model ensemble even more useful. \n",
    "\n",
    "Other observations from several video run-\n",
    "1. Photoframes, rectangular shaped stuffs on shelves, fileplace are often classified as tv (childproof heavy object). Those should be included in 'none' category.\n",
    "\n",
    "2. Anything portruding from wall / wall-like is classified as open-wire (childproof electrical). Those should be included in a  'none' catgory too.\n",
    "\n",
    "3. Switchboard, and small decors with holes are sometimes missclassified as open plug (childproof electrical).\n",
    "\n",
    "4. Some designs on furniture are missclassified as 'stain' or 'distress' . This is same with wall decor, wall texture or any design on wall (wall stain, furniture stain).\n",
    "\n",
    "5. Organized fruits/objects on table are sometimes categorized as part of kitchen. It would be useful to include a 'none' category for childproof heavy object model.\n",
    "\n",
    "6. Object with a particluar shape, e.g., basin, sink etc are sometimes classified as bathtub (childproof fall). \n",
    "\n",
    "Including 'none' category to each model training set would be helpful for designing this model ensemble. The 'none' category should contain all other type of images associated with a building apart from the interest category.\n",
    "\n",
    "Next, I want to implement gradcam in this model to show where the model is focusing for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The video is uploaded in youtube: https://www.youtube.com/watch?v=_aIYhrGMioo&t=23s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
